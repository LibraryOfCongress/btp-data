{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "First, we run the definitions step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 02_definitions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load cached data from the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_cache(\"Susan B. Anthony Papers\")\n",
    "c = read_cache(\"Carrie Chapman Catt Papers\")\n",
    "s = read_cache(\"Elizabeth Cady Stanton Papers\")\n",
    "t = read_cache(\"Mary Church Terrell: Advocate for African Americans and Women\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Susan B. Anthony speech subset\n",
    "A [typed inventory of speeches](http://hdl.loc.gov/loc.mss/ms997009.mss11049.036) in the Susan B. Anthony Papers is available; this allows for subsetting the transcription data so that it can be processed and visualized separately from the entire transcription dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the transcription text for the speeches\n",
    "The code below will group transcription data by the `ItemId`. The speech inventory will then be used to subset the transcription data using the `ItemId` of known speeches. The transcribed text will then be combined at the item level and stored in a dictionary that lists the `id`, `year`, `title`, and `text` of each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfoo\\AppData\\Local\\Temp\\ipykernel_20840\\368432478.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  d = re.findall('\\d{4}', a_speeches.iloc[row][1])\n",
      "C:\\Users\\bfoo\\AppData\\Local\\Temp\\ipykernel_20840\\368432478.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  speech_id = a_speeches.iloc[row][0]\n",
      "C:\\Users\\bfoo\\AppData\\Local\\Temp\\ipykernel_20840\\368432478.py:20: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'title': a_speeches.iloc[row][2],\n"
     ]
    }
   ],
   "source": [
    "# Load the speech inventory\n",
    "a_speeches = load_csv(SPEECHES)\n",
    "\n",
    "# Group transcriptions by ItemId\n",
    "# Creates a dictionary where the ItemId is the key and the value is a list of associated row indexes\n",
    "a_groups = a.groupby('ItemId').groups\n",
    "\n",
    "# Create a list of dictionaries representing each speech\n",
    "# This structure is specifically designed for visualization in the next notebook\n",
    "speech_list = []\n",
    "\n",
    "for row in range(a_speeches.shape[0]):\n",
    "    d = re.findall('\\d{4}', a_speeches.iloc[row][1])\n",
    "    speech_id = a_speeches.iloc[row][0]\n",
    "    speech_text = []\n",
    "    for i in a_groups[speech_id]:\n",
    "        speech_text.extend(a['processed_text'].iloc[i])\n",
    "    speech = {'id': speech_id, \n",
    "              'year': d[0], \n",
    "              'title': a_speeches.iloc[row][2], \n",
    "              'text': speech_text}\n",
    "    speech_list.append(speech)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save `speech_list` to a Python file for import or reuse beyond these notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cache(pd.DataFrame(speech_list), \"anthony_speech_lemmas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process transcription data for all four datasets\n",
    "The following code will prepare the data similar to the Susan B. Anthony speech subset above. Running this code is necessary for visualizing at the dataset-level for all four datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of all words from `processed_text` for each dataset\n",
    "This code will create a dictionary containing the titles and aggregated text from the `processed_text` column for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = []\n",
    "\n",
    "for dataset in [a, c, s, t]:\n",
    "    transcription_text = []\n",
    "    for row in range(dataset.shape[0]):\n",
    "        transcription_text.extend(dataset['processed_text'].iloc[row])\n",
    "    transcription = {'title': dataset['Campaign'][0],\n",
    "                     'text': transcription_text}\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save `transcriptions` to a Python file for import or reuse beyond these notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cache(pd.DataFrame(transcriptions), \"transcriptions_lemmas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
